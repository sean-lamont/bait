{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_eval_bar_chart(eval_record, title=''):\n",
    "    performances = [eval_record[criterion] for criterion in sorted(eval_record.keys())]\n",
    "    criteria = list(sorted(eval_record.keys()))\n",
    "    curricula = sorted(performances[0].keys(), key=lambda x: -len(x))\n",
    "    \n",
    "    df_list = list()\n",
    "    for i, criterion in enumerate(criteria):\n",
    "        for j, curriculum in enumerate(curricula):\n",
    "            df_list.append(\n",
    "                {\n",
    "                    \"curriculum\": curriculum,\n",
    "                    \"eval criterion\": criterion,\n",
    "                    \"success rate\": performances[i][curriculum]\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    df = pd.DataFrame(df_list)\n",
    "    print(df.to_string())\n",
    "    ax = sns.catplot(x=\"eval criterion\", y=\"success rate\", hue=\"curriculum\", data=df,\n",
    "                height=12, kind=\"bar\", palette=\"Paired\", )\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_model_dir = \"/scratch/hdd001/home/ywu/ineqResultsEasy/sl_back_basic\"\n",
    "gen_model_dir = \"/scratch/hdd001/home/ywu/ineqResultsEasy/sl_back_gen\"\n",
    "forward_model_dir = \"/scratch/hdd001/home/ajiang/pt_models/sl_forward_basic\"\n",
    "atten0_model_dir = \"/scratch/hdd001/home/ajiang/pt_models/sl_archi\"\n",
    "fakeforward_model_dir = \"/scratch/hdd001/home/ajiang/ywu/ineqResultsEasy/sl_fake_forward\"\n",
    "model_dirs = [basic_model_dir, gen_model_dir, forward_model_dir, atten0_model_dir, fakeforward_model_dir]\n",
    "eval_dir = \"/scratch/hdd001/home/ajiang/ywu/ineqResultsEasy/elva\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_record_train = dict()\n",
    "all_record_test = dict()\n",
    "for model_dir in model_dirs:\n",
    "    eval_record_train = collections.defaultdict(dict)\n",
    "    for time_stamp in os.listdir(model_dir):\n",
    "        config = json.load(open(os.path.join(model_dir, time_stamp, \"env_config.json\"), \"r\"))\n",
    "        signature = \"Trained on {}, atten {}, lr {}, sd {}, hidden {}, {}\".format(\n",
    "            config[\"train_dirs\"], config[\"atten_type\"], config[\"lr\"], \n",
    "            config[\"state_dim\"], config[\"hidden\"],\n",
    "            \"backward\" if config[\"online_backwards\"] else \"forward\",\n",
    "        \n",
    "        )\n",
    "        eval_rewards = json.load(open(os.path.join(eval_dir, time_stamp, \"eval_rewards.json\"), \"r\"))\n",
    "        for key, value in eval_rewards.items():\n",
    "            eval_record_train[key][signature] = value[\"train\"]\n",
    "    eval_record_test = collections.defaultdict(dict)\n",
    "    for time_stamp in os.listdir(model_dir):\n",
    "        config = json.load(open(os.path.join(model_dir, time_stamp, \"env_config.json\"), \"r\"))\n",
    "        signature = \"Trained on {}\".format(config[\"train_dirs\"])\n",
    "        eval_rewards = json.load(open(os.path.join(eval_dir, time_stamp, \"eval_rewards.json\"), \"r\"))\n",
    "        for key, value in eval_rewards.items():\n",
    "            eval_record_test[key][signature] = value[\"test\"]\n",
    "    \n",
    "    all_record_train[model_dir] = eval_record_train\n",
    "    all_record_test[model_dir] = eval_record_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_bar_chart(\n",
    "    all_record_train['/scratch/hdd001/home/ywu/ineqResultsEasy/sl_back_basic'], \n",
    "    \"Success rate on training combos\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
