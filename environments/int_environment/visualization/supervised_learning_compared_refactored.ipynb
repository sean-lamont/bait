{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def moving_average(input_list, gamma=0):\n",
    "    output_list = list()\n",
    "    ma = input_list[0]\n",
    "    for element in input_list:\n",
    "        ma = gamma * ma + (1-gamma) * element\n",
    "        output_list.append(ma)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_eval(evals):\n",
    "    for i, key in enumerate(evals.keys()):\n",
    "        figure(num=None, figsize=(14, 10*len(evals)), dpi=80, facecolor='w', edgecolor='k')\n",
    "        ax = plt.subplot(len(evals), 1, i+1)\n",
    "        sorted_keys = sorted(list(evals[key][\"eval\"].keys()))\n",
    "        sorted_values = [evals[key][\"eval\"][sorted_key] for sorted_key in sorted_keys]\n",
    "        plt.bar(sorted_keys, sorted_values)\n",
    "        plt.title(key+evals[key][\"trained\"]+\" split: \"+str(evals[key][\"online_train_test_split\"]))\n",
    "        plt.ylim(0, 1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_stuff(phonebook, file_names, title, val=False):\n",
    "    linestyles = ['-', '--', '-.', ':']\n",
    "    colours = ['tab:blue', 'tab:orange','tab:green','tab:red','tab:purple',\n",
    "               'tab:brown','tab:pink','tab:gray','tab:olive','tab:cyan']\n",
    "    group_by_index = dict()\n",
    "    for dir_name, dir_index in phonebook.items():\n",
    "        if dir_index in group_by_index:\n",
    "            group_by_index[dir_index].append(dir_name)\n",
    "        else:\n",
    "            group_by_index[dir_index] = [dir_name]\n",
    "    \n",
    "    for i, dir_index in enumerate(group_by_index.keys()):\n",
    "        figure(num=None, figsize=(14, 10*len(group_by_index)), dpi=80, facecolor='w', edgecolor='k')\n",
    "        ax = plt.subplot(len(group_by_index), 1, i+1)\n",
    "        \n",
    "        for k, dir_name in enumerate(sorted(group_by_index[dir_index])):\n",
    "            colour = colours[k]\n",
    "            print(dir_name)\n",
    "            try:\n",
    "                record = json.load(open(os.path.join(dir_name, \"record.json\"), \"r\"))\n",
    "                config = json.load(open(os.path.join(dir_name, \"env_config.json\"), \"r\"))\n",
    "                for j, file_name in enumerate(file_names):\n",
    "                    style = linestyles[j]\n",
    "                    training_loss = record[file_name]\n",
    "                    batch_size = config[\"batch_size\"]\n",
    "                    display_file_name = file_name.split(\"_\")[0]\n",
    "\n",
    "                    hyper_params = \"bow\" if config[\"bag_of_words\"] else config[\"obs_mode\"][:3]\n",
    "                    if config[\"online\"]:\n",
    "                        hyper_params += \\\n",
    "                            \", online split: {}, epd {}, lr {}, {}\".format(\n",
    "                                config[\"online_train_test_split\"], config[\"epochs_per_online_dataset\"],\n",
    "                                config[\"lr\"], \"Forward\" if \"forward\" in dir_name else \"Backward\"\n",
    "                            )\n",
    "                    print(dir_index, hyper_params, record[\"progress\"])\n",
    "                    if val==\"val\":\n",
    "                        for key, loss in training_loss.items():\n",
    "                            hor_axis = np.array(range(len(loss)))\n",
    "                            quantity_to_plot = moving_average(loss)\n",
    "                            plt.plot(hor_axis, quantity_to_plot, label=hyper_params+\"(diff: {})\".format(key))\n",
    "                            ax.annotate(round(quantity_to_plot[-1], 2), \n",
    "                                        xy=(hor_axis[-1], quantity_to_plot[-1]),\n",
    "                                       linestyle=style,\n",
    "                                       color=colour)\n",
    "                    elif val==\"succ\":\n",
    "                        if isinstance(training_loss, list):\n",
    "                            hor_axis = np.array(range(len(training_loss))) * \\\n",
    "                                config[\"epoch_per_case_record\"] * config[\"problems\"]\n",
    "                            quantity_to_plot = moving_average(training_loss, 0.97)\n",
    "                            plt.plot(hor_axis, quantity_to_plot, label=hyper_params+\" \"+display_file_name,\n",
    "                                       linestyle=style,\n",
    "                                       color=colour)\n",
    "                            ax.annotate(round(quantity_to_plot[-1], 2), \n",
    "                                        xy=(hor_axis[-1], quantity_to_plot[-1]))\n",
    "                        else:\n",
    "                            for key, loss in training_loss.items():\n",
    "                                hor_axis = np.array(range(len(loss))) \\\n",
    "                                    * config[\"epoch_per_case_record\"] * config[\"problems\"]\n",
    "                                quantity_to_plot = moving_average(loss)\n",
    "                                plt.plot(hor_axis, quantity_to_plot, label=hyper_params+\"(diff: {})\".format(key),\n",
    "                                       linestyle=style,\n",
    "                                       color=colour)\n",
    "                                ax.annotate(round(quantity_to_plot[-1], 2), \n",
    "                                            xy=(hor_axis[-1], quantity_to_plot[-1]))\n",
    "                                print(key, round(quantity_to_plot[-1], 2))\n",
    "                    else:\n",
    "                        quantity_to_plot = moving_average(np.array(training_loss))\n",
    "                        hor_axis = np.array(range(len(training_loss))) * config[\"problems\"]\n",
    "                        plt.plot(hor_axis, quantity_to_plot, label=hyper_params,\n",
    "                                       linestyle=style,\n",
    "                                       color=colour)\n",
    "                        ax.annotate(round(quantity_to_plot[-1], 2), \n",
    "                                    xy=(hor_axis[-1], quantity_to_plot[-1]))\n",
    "            except Exception as e:\n",
    "                print(dir_name)\n",
    "                print(\"Exception: {}\".format(e))\n",
    "                pass\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Problems trained\")\n",
    "        \n",
    "        ax.set_title(\"{}: {}\".format(title, dir_index))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"/scratch/hdd001/home/ajiang/pt_models/sl_backward_basic\"\n",
    "dir_phonebook = dict()\n",
    "dir_evals = dict()\n",
    "for dir_name in os.listdir(directory):\n",
    "    if os.path.isdir(os.path.join(directory, dir_name)) and (not dir_name.startswith('.')):\n",
    "        if \"2020_01_16\" < dir_name:\n",
    "            config = json.load(open(os.path.join(directory, dir_name, \"env_config.json\"), \"r\"))\n",
    "            config_index = config['train_dirs']\n",
    "            if isinstance(config_index, list):\n",
    "                train_index = \", \".join([single_index.split(\"/\")[-1] for single_index in config_index])\n",
    "                test_index = \", \".join([single_index.split(\"/\")[-1] for single_index in config[\"test_dirs\"]])\n",
    "            online = config[\"online\"]\n",
    "            if online:\n",
    "                actual_l_train = int((int(str(config[\"train_dirs\"])[-3]) + 1) / 2)\n",
    "                train_config = str(config[\"train_dirs\"])[:-3] + str(actual_l_train) + str(config[\"train_dirs\"])[-2:]\n",
    "                actual_l_test = int((int(str(config[\"test_dirs\"])[-3]) + 1) / 2)\n",
    "                test_config = str(config[\"test_dirs\"])[:-3] + str(actual_l_test) + str(config[\"test_dirs\"])[-2:]\n",
    "                print(train_config, test_config)\n",
    "#                 train_config, test_config = config[\"train_dirs\"], config[\"test_dirs\"]\n",
    "                dir_phonebook[os.path.join(directory, dir_name)] = \\\n",
    "                    \"Trained on {} and tested on: {}\".format(train_config, test_config)\n",
    "            else:\n",
    "                dir_phonebook[os.path.join(directory, dir_name)] = \\\n",
    "                    \"Trained on: {}; Tested on: {}\".format(train_index, test_index)\n",
    "            \n",
    "            dir_evals[dir_name] = {\n",
    "                \"trained\": \"k={}, l={}\".format(config[\"axioms\"], config[\"length\"]),\n",
    "                \"online_train_test_split\": config[\"online_train_test_split\"],\n",
    "                \"eval\": {}\n",
    "            }\n",
    "            for eval_name in os.listdir(os.path.join(directory, dir_name)):\n",
    "                if eval_name.startswith(\"k\"):\n",
    "                    sr = json.load(open(os.path.join(directory, dir_name, eval_name), \"r\"))\n",
    "                    dir_evals[dir_name][\"eval\"][eval_name.split(\".\")[0]] = sr\n",
    "                    \n",
    "configs = dict()\n",
    "for dir_name in dir_phonebook:\n",
    "    config = json.load(open(os.path.join(dir_name, \"env_config.json\"), \"r\"))\n",
    "    if \"gnn_type\" in config and \"hidden_layers\" in config:\n",
    "        configs[dir_name.split(\"/\")[2]] = {\n",
    "            \"learning rate\": config[\"lr\"],\n",
    "            \"epoch\": config[\"epoch\"],\n",
    "            \"state dimension\": config[\"state_dim\"],\n",
    "            \"batch size\": config[\"batch_size\"],\n",
    "            \"problem index\": \"{}-{}\".format(config[\"train_val_diffs\"][0], config[\"train_val_diffs\"][-1]),\n",
    "            \"gnn_type\": config[\"gnn_type\"],\n",
    "            \"lr_decay\": config[\"lr_decay\"],\n",
    "            \"hidden_layers\": config[\"hidden_layers\"],\n",
    "            \"train_val_diffs\": config[\"train_val_diffs\"],\n",
    "            \"test_diffs\": config[\"test_diffs\"]\n",
    "        }\n",
    "config_df = pd.DataFrame(configs)\n",
    "config_df.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "forward_book = deepcopy(dir_phonebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"train_losses\"], \"Training cross entropy: lemma and entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"train_lemma_accs\"], \"Training lemma accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"test_lemma_accs\"], \"Test lemma accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"train_ent_accs\"], \"Training entity accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"test_ent_accs\"], \"Test entity accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"train_first_success_rates\"], \n",
    "           \"Training success rate\", val=\"succ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"test_first_success_rates\"], \n",
    "           \"Success rate\", val=\"succ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stuff(dir_phonebook, [\"train_first_success_rates\", \"test_first_success_rates\"], \n",
    "           \"Success rate\", val=\"succ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
