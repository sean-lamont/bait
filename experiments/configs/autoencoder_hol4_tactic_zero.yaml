epochs: 800
max_steps: 5
pretrain: False
proof_db: ['hol4', 'proof_logs']
# tactic_config
exp_config:
  name: "vanilla"
  resume: True
  experiment: "tactic_zero"
  directory: "experiments/runs/tacticzero/vanilla/vanilla_2023-07-28-01:33:12"
  logging_config:
    project: "rl_new"
    offline: False
    id: 'hn44k9lf'
#    notes: "Vanilla"
optimiser_config:
  learning_rate: 5e-5
model_config:
  model_type: "fixed_autoencoder"
  model_attributes:
    # checkpoint to fixed, pretrained autoencoder from original TacticZero paper
    checkpoint_path: "experiments/hol4_tactic_zero/rl/old/model_checkpoints/best_vanilla/2021_02_22_16_07_03"
  vocab_size: 2015
  embedding_dim: 256
data_config:
  type: "fixed"
  source: "mongodb" #directory
  shuffle: True
  data_options:
    filter: ['tokens', 'edge_attr', 'edge_index']
    db: 'hol4_original_ast'
    expression_col: 'expression_graphs'
    vocab_col: 'vocab'
    split_col: 'paper_goals'
    environment: 'HOL4'

#  attributes:
  # attention_edge_index: 'directed'
  # pe: 'depth'
#  dir: "data/hol4/graph_attention_data_new"
#val_frequency: 128
