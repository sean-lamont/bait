# @package _global_
defaults:
  - /base/logging_config@_here_
  - /base/exp_config@_here_

exp_config:
  name: test
  experiment: end_to_end_holist

logging_config:
  project: end_to_end_holist
  offline: true

env: holist
data_path: data/leandojo/data/leandojo_benchmark/random/
split: test
file_path: null
full_name: null
num_theorems: 2000
shuffle: false
name_filter: null
name: null
indexed_corpus_path: null
num_sampled_tactics: 64
total_timeout: 6000
env_timeout: 60
with_gpus: true
log_level: 'INFO'
logical_gpus: 1
num_gpus: 1
num_cpus: 16
gpu_per_prover: 0.01
cpu_per_prover: 1
provers_per_gpu: 4

env_config:
  path_theorem_database: 'data/holist/theorem_database_v1.1.textpb'

tac_model:
  model: holist
  ckpt_path: null
  distributed: true
  gpu_per_process: 0.9
  cpu_per_process: 1
  action_generator_options:
    random_tactic_probability: 0.5
    bag_of_words_similar: false
    max_theorem_parameters: 5
    asm_meson_only: false
    asm_meson_no_params_only: false
  #    num_similar_parameters:
  #      max_value: null
  #      min_value: null


  # Setting ProverOptions Proto
  path_tactics: 'experiments/configs/holist/hollight_tactics.textpb'
  path_tactics_replace: 'experiments/configs/holist/hollight_tactics_replacements.textpb'
  path_theorem_database: 'data/holist/theorem_database_v1.1.textpb'

  model_architecture: PARAMETERS_CONDITIONED_ON_TAC
  theorem_embeddings: 'experiments/holist/checkpoints/checkpoint.npy'
  path_model_prefix: 'experiments/holist/checkpoints/checkpoint'

  data_config:
    attributes: {}
    batch_size: 16
    # todo should just be attributes of loaded model
    type: graph
    data_options:
      db: 'holist'
      filter: ['tokens', 'edge_index', 'edge_attr']
      vocab_col: vocab


  model_config:
    model_type: holist_gnn
    model_attributes:
      gnn_layers: 0 # change to 0 for BoW
      dropout: 0.2
      embedding_dim: 128
      vocab_size: 1500

search_model:
  search: bestfs