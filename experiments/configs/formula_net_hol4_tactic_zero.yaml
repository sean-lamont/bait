epochs: 800
max_steps: 5
pretrain: False
pretrain_ckpt: ''#'experiments/runs/premise_selection/2023_07_28/formula_net_19_24_20/checkpoints/epoch=9-acc=0.9163475036621094.ckpt'
proof_db: ['hol4', 'proof_logs']
# tactic_config
exp_config:
  name: "formula_net_2_layer_pretrain"
  resume: True
  experiment: "tactic_zero"
  directory: "experiments/runs/tactic_zero/formula_net_2_layer_pretrain_2023-07-29-16:04:08"
  logging_config:
    project: "rl_new"
    offline: False
    id: 'wp30q42c'
    notes: "FormulaNet 2 Layer Pretrained 5 Step"
optimiser_config:
  learning_rate: 5e-5
model_config:
  model_type: "formula-net-edges"
  model_attributes:
    vocab_size: 2200
    embedding_dim: 256
    gnn_layers: 2
    batch_norm: False
  vocab_size: 2200
  embedding_dim: 256
data_config:
  type: "graph"
  source: "mongodb" #directory
  shuffle: True
  data_options:
    filter: ['tokens', 'edge_attr', 'edge_index']
    db: 'hol4_original_ast'
    expression_col: 'expression_graphs'
    vocab_col: 'vocab'
    split_col: 'paper_goals'
    environment: 'HOL4'
#  attributes:
  # attention_edge_index: 'directed'
  # pe: 'depth'
#  dir: "data/hol4/graph_attention_data_new"
#val_frequency: 128
