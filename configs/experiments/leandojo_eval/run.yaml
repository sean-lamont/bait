# @package _global_
defaults:
  - /base/logging_config@_here_
  - /base/exp_config@_here_

exp_config:
  name: test
  experiment: test

logging_config:
  project: end_to_end
  offline: true

# environment to use (leandojo, holist))
env: leandojo

# todo config for getting theorems from environment
data_path: data/leandojo/data/leandojo_benchmark/random/
#split: train
split: test
file_path: null
full_name: null
name_filter: null

#num_theorems: 94000 #2000
num_theorems: 1

# whether to shuffle the loaded theorems before evaluation
shuffle: false

name: null
indexed_corpus_path: null

num_sampled_tactics: 64

# Total time allowed for a single proof attempt
total_timeout: 6000

# Maximum time allowed in environment before timing out
env_timeout: 10


with_gpus: true
log_level: 'INFO'

# Resource configuration
logical_gpus: 1
num_gpus: 1
num_cpus: 16
gpu_per_prover: 0.01
cpu_per_prover: 1
provers_per_gpu: 1

# Number of End-to-End Eval -> Train -> Eval loops
num_iterations: 2
resume_iteration: 0

tac_model:
  model: reprover
  ckpt_path: gen.ckpt
  distributed: true
  gpu_per_process: 0.45
  cpu_per_process: 1
  config:
    model_name: kaiyuy/leandojo-lean3-tacgen-byt5-small
    lr: 5e-6
    warmup_steps: 200
    length_penalty: 0.0
    num_beams: 64
    ret_ckpt_path: null
    max_seq_len: 2300
    gen_config:
      strategy: beam
      length_penalty: 0.0
    eval_config: null

search_model:
#  search: bestfs
    search: updown
    ckpt_path: goal_model.ckpt
    distributed: true
    gpu_per_process: 0.45 #0.225
    cpu_per_process: 1 # 0.5

  #    search: htps
  #    ckpt_path: goal_model.ckpt # goal_step.ckpt
  #    distributed: true
  #    gpu_per_process: 0.45
  #    cpu_per_process: 0.5
  #    exploration_constant: 1

  #  search: updown
  #  ckpt_path: goal_model.ckpt
  #  distributed: true
  #  gpu_per_process: 0.45 #0.225
  #  cpu_per_process: 1 # 0.5

# commands to run for retraining the model after every evaluation
train_after_eval:
  - python3 -m refactor.lightning_experiment --config-name=goal_model/run data_module.trace_files=${exp_config.directory}/traces
#  - python3 -m refactor.lightning_experiment --config-name=tac_gen/run data_module.trace_files=${exp_config.directory}/traces

# the model and checkpoint attribute to update.
# Must be same length as train_after_eval, with each index corresponding to the associated command
update_checkpoints:
  - [search_model, ckpt_path]
#  - [tac_model, ckpt_path]