{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_traces(path):\n",
    "    files = glob.glob(path)\n",
    "\n",
    "    traces = []\n",
    "    for file in tqdm(files):\n",
    "        with open(file, \"rb\") as f:\n",
    "            trace = pickle.load(f)\n",
    "            traces.append(trace)\n",
    "    return traces\n",
    "\n",
    "\n",
    "# traces = get_traces('../experiments/runs/eval_loop/leandojo_eval_2023_11_08/17_37_14/traces/*')\n",
    "# traces = get_traces('../experiments/runs/eval_loop/leandojo_eval_2023_11_10/12_32_48/traces/*')\n",
    "traces = get_traces('../experiments/runs/eval_loop/goal_model_2023_11_17/18_11_05/traces/*')\n",
    "# traces.extend(get_traces('../traces_2023-10-31_17:28/*'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traces[1].tree.out_edges[10]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(traces)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from refactor.proof_node import Status, ErrorNode\n",
    "\n",
    "len([t for t in traces if t.tree.status == Status.FAILED])/ len(traces)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc721a2b3711b8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len([t for t in traces if t.tree.status == Status.PROVED])/ len(traces)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "failed = [t for t in traces if t.tree.status == Status.FAILED and not isinstance(t.tree, ErrorNode)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "failed[2].nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trace = failed[28]\n",
    "print (trace.num_expansions)\n",
    "[(node.visit_count, node.is_explored) for node in trace.nodes.values()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "failed[28].tree.out_edges[-4]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "failed[4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from experiments.reprover.render_proof import render_full_trace, render_nx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec81f47539210b60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "render_full_trace(traces[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6862daf0e2e89b1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.mem_get_info('cuda:0')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4e6715a1794d4c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from refactor.proof_node import InternalNode, ErrorNode, ProofFinishedNode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client['lean_dojo']\n",
    "collection = db['goal_data']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "def add_goal_data(node, visits):\n",
    "    steps = node.distance_to_proof\n",
    "    # todo add up_score as new estimate? only after certain visit_threshold\n",
    "\n",
    "    datum = {\n",
    "        'goal': node.goal,\n",
    "        'distance_to_proof': steps,\n",
    "        'visits': visits[node.goal],\n",
    "        'local_visits': len(node.out_edges) if node.out_edges else 0,\n",
    "        'score': node.up_score.item() if isinstance(node.up_score, torch.Tensor) else node.up_score\n",
    "    }\n",
    "\n",
    "    return datum\n",
    "\n",
    "for trace in tqdm(traces):\n",
    "    if isinstance(trace.tree, ErrorNode):\n",
    "        continue\n",
    "    nodes = trace.nodes\n",
    "    nodes[trace.tree.goal] = trace.tree\n",
    "\n",
    "    updated_visit_count = {node: nodes[node].visit_count for node in nodes.keys()}\n",
    "\n",
    "    for goal, node in nodes.items():\n",
    "        for a in node.ancestors:\n",
    "            updated_visit_count[a] += node.visit_count\n",
    "\n",
    "    for node in nodes:\n",
    "        step_datum = add_goal_data(nodes[node], updated_visit_count)\n",
    "        if step_datum:\n",
    "            collection.insert_one(step_datum)\n",
    "            # goal_step_data.append(step_datum)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "collection = db['edge_data']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_edge_data(trace):\n",
    "    data = []\n",
    "    for i, edge in enumerate(trace.tac_trace):\n",
    "        datum = {\n",
    "            'iteration': 0,\n",
    "            'step': i,\n",
    "            'top_goal': trace.theorem,\n",
    "            'goal': edge.src.goal,\n",
    "            'tactic': edge.tactic,\n",
    "            'goal_prob': edge.src.cumulative_logprob,\n",
    "            'tac_prob': edge.logprob,\n",
    "            'distance_to_proof': edge.distance_to_proof(),\n",
    "            'visits': edge.visit_count(),\n",
    "            'time': edge.time,}\n",
    "        # add children of edge\n",
    "        if len(edge.dst) == 1 and isinstance(edge.dst[0], ErrorNode):\n",
    "            # todo could record error message for e.g. self-correcting proof approach>\n",
    "            datum['outcome'] = ['Error']\n",
    "        elif len(edge.dst) == 1 and isinstance(edge.dst[0], ProofFinishedNode):\n",
    "            datum['outcome'] = ['Proven']\n",
    "        else:\n",
    "            outcome = [d.goal for d in edge.dst]\n",
    "            datum['outcome'] = outcome\n",
    "        data.append(datum)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# edge_data = []\n",
    "\n",
    "for trace in tqdm(traces):\n",
    "    if isinstance(trace.tree, ErrorNode):\n",
    "        continue\n",
    "    collection.insert_many(get_edge_data(trace))\n",
    "    # edge_data.extend(get_edge_data(trace))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(traces[6].tac_trace)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traces[0].num_expansions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_rand_idx(collection):\n",
    "    collection.update_many({'rand_idx': {'$exists': False} },\n",
    "        [{'$set':\n",
    "                {'rand_idx': {\n",
    "                    '$function': {\n",
    "                        'body': 'function() {return Math.random();}',\n",
    "                        'args': [],\n",
    "                        'lang': \"js\"\n",
    "                    }\n",
    "                    }}\n",
    "        }]\n",
    "        )\n",
    "\n",
    "    collection.create_index('rand_idx')\n",
    "    return\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rank_collection = db['tac_ranks']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_goal(goal_datum, max_len=10, visit_threshold=2048):\n",
    "    proof_len = goal_datum['distance_to_proof']\n",
    "    if proof_len < max_len:\n",
    "        return {'goal': goal_datum['goal'], 'target': (max_len + 1) - goal_datum['distance_to_proof']}\n",
    "    elif proof_len < math.inf:\n",
    "        return {'goal': goal_datum['goal'], 'target': 1}\n",
    "    elif goal_datum['visits'] >= visit_threshold:\n",
    "        return {'goal': goal_datum['goal'], 'target': 0}\n",
    "    else:\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_goal_proven(goal_datum, visit_threshold=2048):\n",
    "    proof_len = goal_datum['distance_to_proof']\n",
    "    if proof_len < math.inf:\n",
    "        return {'goal': goal_datum['goal'], 'target': 1}\n",
    "    elif goal_datum['visits'] >= visit_threshold:\n",
    "        return {'goal': goal_datum['goal'], 'target': 0}\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "goal_collection = db['goal_data']\n",
    "\n",
    "goal_len_collection = db['goal_len_task']\n",
    "\n",
    "for datum in tqdm(goal_collection.find()):\n",
    "    len_data = transform_goal(datum)\n",
    "    if len_data:\n",
    "        goal_len_collection.insert_one(len_data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "goal_proven_task = db['goal_proven_task']\n",
    "\n",
    "for datum in tqdm(goal_collection.find()):\n",
    "    len_data = transform_goal_proven(datum)\n",
    "    if len_data:\n",
    "\n",
    "        goal_proven_task.insert_one(len_data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_rand_idx(goal_len_collection)\n",
    "add_rand_idx(goal_proven_task)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# create pairs of winners/losers based on edges from a given goal, and maintain tac probs for each\n",
    "# e.g. edges = find({'goal': 'goal'}).edges\n",
    "def rank_edges(goal, edges):\n",
    "    valid_edges = [edge for edge in edges if not isinstance(edge.dst[0], ErrorNode)]\n",
    "    invalid_edges = [edge for edge in edges if isinstance(edge.dst[0], ErrorNode)]\n",
    "\n",
    "    # rank all valid_edges above all invalid_edges\n",
    "    w_l = [{'goal': goal, 'winner': w.tactic, 'winner_prob': w.logprob, 'loser': l.tactic, 'loser_prob': l.logprob, 'type': 'valid_rank'} for w in valid_edges for l in invalid_edges]\n",
    "\n",
    "    # from valid_edges, rank proven goals above non_proven valid goals\n",
    "    proven_edges = [edge for edge in valid_edges if edge.distance_to_proof() < math.inf]\n",
    "    success_non_proven_edges = [edge for edge in valid_edges if edge.distance_to_proof() == math.inf]\n",
    "\n",
    "    w_l.extend([{'goal': goal, 'winner': w.tactic, 'winner_prob': w.logprob, 'loser': l.tactic, 'loser_prob': l.logprob, 'type': 'proven_rank'} for w in proven_edges for l in success_non_proven_edges])\n",
    "\n",
    "    # from proven edges, rank based on distance_to_proof, then execution time\n",
    "    ranked_proofs = sorted(proven_edges, key=lambda x: (x.distance_to_proof(), x.time))\n",
    "\n",
    "    w_l.extend(\n",
    "         [{ 'goal': goal, 'winner': ranked_proofs[i].tactic,\n",
    "            'winner_prob': ranked_proofs[i].logprob,  'loser': ranked_proofs[j].tactic, 'loser_prob': ranked_proofs[j].logprob,\n",
    "            'type': 'time_len_rank' } for i in range(len(ranked_proofs)) for j in\n",
    "          range(i + 1, len(ranked_proofs))])\n",
    "\n",
    "\n",
    "    # among successful without proof, rank those that lead to the same outcome based on time only\n",
    "    for i, edge in enumerate(success_non_proven_edges):\n",
    "        same_outcome_ranks = []\n",
    "        for j in range((i + 1), len(success_non_proven_edges)):\n",
    "            edge_2 = success_non_proven_edges[j]\n",
    "            edge_1_outcome = [g.goal for g in edge.dst] if isinstance(edge.dst[0], InternalNode) else ['Error'] if isinstance(edge.dst[0], ErrorNode) else ['Proven']\n",
    "            edge_2_outcome = [g.goal for g in edge_2.dst] if isinstance(edge_2.dst[0], InternalNode) else ['Error'] if isinstance(edge_2.dst[0], ErrorNode) else ['Proven']\n",
    "            if set(edge_1_outcome) == set(edge_2_outcome):\n",
    "                if edge.time < edge_2.time:\n",
    "                    same_outcome_ranks.append({'goal': goal, 'winner': edge.tactic, 'winner_prob':  edge.logprob, 'loser': edge_2.tactic, 'loser_prob':  edge_2.logprob, 'type': 'same_outcome'})\n",
    "                else:\n",
    "                    same_outcome_ranks.append({'goal': goal, 'winner': edge_2.tactic, 'winner_prob':  edge_2.logprob, 'loser': edge.tactic, 'loser_prob':  edge.logprob, 'type': 'same_outcome'})\n",
    "\n",
    "        w_l.extend(same_outcome_ranks)\n",
    "\n",
    "    if w_l:\n",
    "        rank_collection.insert_many(w_l)\n",
    "    return\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all_goals = [edge['goal'] for edge in tqdm(collection.find())]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all_goals = set(all_goals)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# data = []\n",
    "# for goal in tqdm(all_goals):\n",
    "for trace in tqdm(traces):\n",
    "    # test_edges = [edge for edge in collection.find({'goal': goal})]\n",
    "    # goal, winners, losers = rank_edges(goal=goal, edges=test_edges)\n",
    "    if isinstance(trace.tree, ErrorNode):\n",
    "        continue\n",
    "    nodes = trace.nodes\n",
    "    nodes[trace.tree.goal] = trace.tree\n",
    "\n",
    "    for node in nodes.values():\n",
    "        if node.out_edges:\n",
    "            rank_edges(goal=node.goal, edges=node.out_edges)\n",
    "    # data.append((goal, winners, losers))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_rand_idx(rank_collection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "goal_collection = db['goal_data']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_rand_idx(goal_collection)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "goal, winners, losers = data[8]\n",
    "\n",
    "\n",
    "len(winners)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 419\n",
    "print (winners[i])\n",
    "print (losers[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = -6\n",
    "print (winners[i])\n",
    "losers[i]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo method to reconstruct search tree based on edge data above\n",
    "# run normal search process, replace run_tac with outcome -> edge, replace get_goals with goal, replace get_tactics with tactic\n",
    "# useful for reward based goal models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo how to merge different attempts of same proof?\n",
    "# For goal data, if proof length is lower, take that data point. If failed, and visit count higher, replace with that as well\n",
    "# I.e. every new attempt, add all new goals, and also update existing goals with above criteria\n",
    "\n",
    "# For edge data...\n",
    "# Assume all valid/invalid edges are still valid/invalid, then those rankings are fine\n",
    "# Rankings from proven/success could be changed if success turns out to be a proof..\n",
    "# Rankings within proof could also change, if shorter proof from children is found\n",
    "# Seems small/unlikely for this to make much of a difference. Worst case is a longer proof is ranked better than a shorter/slower one\n",
    "\n",
    "# Don't just keep best trace, since we may discard useful old goals\n",
    "# Best trace given by the trace with the shortest proof...\n",
    "\n",
    "\n",
    "# todo check logits of forward match those from generation\n",
    "\n",
    "# todo train scripts for eval models\n",
    "\n",
    "# todo htps\n",
    "\n",
    "# todo add BFS, bestfs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run in environment"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
