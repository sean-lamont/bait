{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from refactor.generator.model import RetrievalAugmentedGenerator\n",
    "from refactor.dpo.model import DPOTrainModule\n",
    "\n",
    "ckpt_path = '../dpo.ckpt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tac_gen = DPOTrainModule.load(\n",
    "#     ckpt_path, device='cuda', freeze=False\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tac_gen = RetrievalAugmentedGenerator.load(\n",
    "    ckpt_path, device='cuda', freeze=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tac_gen.batch_generate([trace.tree])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gen(state):\n",
    "    tokenized_state = tac_gen.tokenizer(\n",
    "    state,\n",
    "    padding=\"longest\",\n",
    "    max_length=2300,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    state_ids = tokenized_state.input_ids.to('cuda')\n",
    "    state_mask = tokenized_state.attention_mask.to('cuda')\n",
    "\n",
    "    # )\n",
    "    #\n",
    "    output = tac_gen.generator.generate(\n",
    "    input_ids=state_ids,\n",
    "    attention_mask=state_mask,\n",
    "    max_length=2300,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=8,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True,\n",
    "    top_p=0.95,\n",
    "    )\n",
    "\n",
    "\n",
    "    return output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "output = gen(trace.tree.goal)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transitions = tac_gen.generator.compute_transition_scores(output.sequences, output.scores, normalize_logits=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transitions.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transitions[transitions != -torch.inf]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.sum(transitions[3][transitions[3] != -torch.inf])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tac_gen.tokenizer.decode(output.sequences[7])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transitions[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for tok, score in zip(output.sequences[2], transitions[2]):\n",
    "    print (tac_gen.tokenizer.decode(tok),score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tac_gen.tokenizer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (torch.sum(torch.nonzero(output.sequences[0])[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output.sequences.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(output.scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = torch.stack(output.scores, dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores[0][scores[0] > -torch.inf]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.gather(scores[0], 1,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(scores[0] > -torch.inf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.nonzero(scores[0] != -torch.inf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from peft import LoraModel, LoraConfig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tac_gen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_modules = ['q', 'k', 'v', 'o', 'wo', 'lm_head']\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.01,\n",
    ")\n",
    "\n",
    "model = tac_gen.generator\n",
    "lora_model = LoraModel(model, config, \"default\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "peft_model = get_peft_model(model, config)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peft_model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from refactor.process_traces import get_traces\n",
    "\n",
    "trace = get_traces('../experiments/runs/eval_loop/bestfs_2023_11_16/07_59_20/traces/abs_sub_round_eq_min')[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (tac_gen)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reconstruct_scores(state, sequence):\n",
    "    tokenized_sequence= tac_gen.tokenizer(\n",
    "        sequence,\n",
    "        padding=\"longest\",\n",
    "        max_length=2300,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    tokenized_state = tac_gen.tokenizer(\n",
    "        state,\n",
    "        padding=\"longest\",\n",
    "        max_length=2300,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    state_ids = tokenized_state.input_ids.cuda()\n",
    "    state_mask = tokenized_state.attention_mask.cuda()\n",
    "\n",
    "    targets = tokenized_sequence.input_ids.cuda()\n",
    "\n",
    "    targets[targets == tac_gen.tokenizer.pad_token_id] = -100\n",
    "\n",
    "\n",
    "\n",
    "    output = tac_gen.generator(\n",
    "        input_ids=state_ids,\n",
    "        attention_mask=state_mask,\n",
    "        labels=targets\n",
    "    ).logits\n",
    "\n",
    "    return output, tokenized_sequence.input_ids.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edges = trace.tree.out_edges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[(e, e.distance_to_proof(), e.dst[0].status) for e in edges]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trace.tree.out_edges[:2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "tacs = ['rw <a>round_eq</a>']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logits, seq_ids = reconstruct_scores([trace.tree.goal], tacs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalised = torch.log_softmax(logits, -1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outs = torch.gather(normalised, -1, seq_ids.unsqueeze(-1)).squeeze(-1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outs[seq_ids == tac_gen.tokenizer.pad_token_id] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.sum(outs, dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
